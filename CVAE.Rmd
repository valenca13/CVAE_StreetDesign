---
title: "Conditional Variational Autoencoder"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##### 1. Import libraries

```{r message=FALSE, warning=FALSE}
# With TF-2, you can still run this code due to the following line:
if (tensorflow::tf$executing_eagerly())
  tensorflow::tf$compat$v1$disable_eager_execution()

library(keras)
K <- keras::backend()

#library(keras)
library(tidyverse)
library(imager)
library(recolorize)
library(OpenImageR)
library(readxl)
```

##### 2. Import dataset

```{r}
files_train <- list.files("Dataset/Images/Train_filtered",  full.names = TRUE, pattern = ".jpg", all.files = TRUE)
#files_train_labels <- list.files("Dataset/Features/Features_Class_Train/",  full.names = TRUE, pattern = ".txt", all.files = TRUE)
labels_train <- read_excel('Dataset/Features/Features_Dummy_Train/Labels_Dummy.xlsx')

files_test <- list.files("Dataset/Images/Test_filtered",  full.names = TRUE, pattern = ".jpg", all.files = TRUE)
#files_test_labels <- list.files("Dataset/Features/Features_Class_Test/",  full.names = TRUE, pattern = ".txt", all.files = TRUE)
labels_test <- read_excel('Dataset/Features/Features_Dummy_Test/Labels_Dummy_test.xlsx')

```

##### 3.Data preprocessing 

**a) Training data**

* **IMAGES**

######  Resize images and assign to a list 
```{r}
Results_train <- list()
for(i in seq_along(files_train)){
  Image <- readImage(files_train[i]) 
  Resized <- resizeImage(Image, width = 24, height = 32) #uniform size of images
  Results_train[[i]] <- Resized
}
```

###### Check the number of dimensions

```{r}
dim(Results_train[[2]])
```

###### Show an example of an image from the training dataset

```{r}
imageShow(Results_train[[300]])
```

###### Convert list of images into arrays

```{r}
train_array <- array(unlist(Results_train), dim=c(1265,24,32,3))
dim(train_array)
```

* **FEATURES** 

###### Convert features into a Dummy (with or without an object). Filter only the feature: with or without pedestrians. 

```{r}
labels_train$X.person. <- as.integer(labels_train$X.person.)
y_t <- data.frame(labels_train[-c(1:3)]) %>% 
  as.matrix()
y_train <- to_categorical(y_t, num_classes = NULL, dtype="float32") 
```

**b) Test data**

* **IMAGES**

###### Resize images and assign to a list 
```{r}
Results_test <- list()
for(i in seq_along(files_test)){
  Image <- readImage(files_test[i])
  Resized <- resizeImage(Image, width = 240, height = 320)
  Results_test[[i]] <- Resized
}
```


###### Check the number of dimensions

```{r}
dim(Results_test[[2]])
```

###### Show an example of an image from the test dataset

```{r}
imageShow(Results_test[[3]])
```

###### Convert list of images into arrays

```{r}
test_array <- array(unlist(Results_test), dim=c(243,24,32,3))
```

* **FEATURES**

###### Convert features into a Dummy (with or without an object). Filter only the feature: with or without pedestrians.

```{r}
labels_test$X.person. <- as.integer(labels_test$X.person.)
y_te <- data.frame(labels_test[-c(1:3)]) %>% 
  as.matrix() 
y_test <- to_categorical(y_te, num_classes = NULL, dtype = "float32") 
```


##### VARIATIONAL AUTOENCODER

## Input image dimensions

img_rows <- 24L
img_cols <- 32L
img_channels <- 3L # Greyscale = 1 and RGB = 3


